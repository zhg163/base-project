对系统模型服务进行设计。
1、使用langchain 管理记忆、多模型切换 、支持根据角色选择使用prompt 、根据敏感词、日常沟通判断是否执行回复和rag调用 
2、回复支持 基础、 流式 、sse 
3、抽象出功能单一的类，处理单一功能
4、配置模型配置从.env中获取
# 系统架构图
app/
├── services/
│   ├── ai/
│   │   ├── llm/
│   │   │   ├── base_llm_service.py      # 基础模型服务接口
│   │   │   ├── deepseek_service.py      # Deepseek模型实现
│   │   │   ├── qianwen_service.py       # qianwen模型实现（可选）
│   │   │   └── llm_factory.py           # 模型工厂
│   │   │
│   │   ├── memory/
│   │   │   ├── memory_service.py        # 记忆服务
│   │   │   └── redis_memory.py          # Redis记忆实现
│   │   │
│   │   ├── prompt/
│   │   │   ├── prompt_service.py        # 提示词服务
│   │   │   ├── role_prompts.py          # 角色提示词
│   │   │   └── system_prompts.py        # 系统提示词
│   │   │
│   │   ├── filter/
│   │   │   ├── content_filter.py        # 内容过滤服务
│   │   │   ├── sensitive_words.py       # 敏感词处理
│   │   │   └── intent_classifier.py     # 意图分类
│   │   │
│   │   ├── rag/
│   │   │   ├── rag_service.py           # RAG检索服务
│   │   │   └── document_store.py        # 文档存储
│   │   │
│   │   └── response/
│   │       ├── response_formatter.py    # 响应格式化
│   │       ├── sse_formatter.py         # SSE格式化
│   │       └── stream_formatter.py      # 流式格式化
│   │
│   └── chat_service.py                  # 聊天服务（编排各组件）

# 1. 整体聊天流程
sequenceDiagram
    participant User
    participant ChatService
    participant FilterService
    participant MemoryService
    participant PromptService
    participant RAGService
    participant LLMService
    participant ResponseService

    User->>ChatService: 发送消息
    ChatService->>FilterService: 内容过滤检查
    
    alt 内容需要过滤
        FilterService-->>ChatService: 拒绝请求
        ChatService-->>User: 返回过滤消息
    else 内容通过
        FilterService-->>ChatService: 内容通过
        ChatService->>MemoryService: 获取历史对话
        MemoryService-->>ChatService: 返回历史对话
        
        ChatService->>PromptService: 获取角色提示词
        PromptService-->>ChatService: 返回提示词
        
        ChatService->>FilterService: 判断是否需要RAG
        
        alt 需要RAG增强
            ChatService->>RAGService: 获取相关文档
            RAGService-->>ChatService: 返回检索结果
        end
        
        ChatService->>LLMService: 调用语言模型
        LLMService-->>ChatService: 返回模型响应
        
        ChatService->>ResponseService: 格式化响应
        ResponseService-->>ChatService: 返回格式化结果
        
        ChatService->>MemoryService: 保存对话历史
        ChatService-->>User: 返回响应
    end
# 2. LLM服务流程
flowchart TD
    A[请求开始] --> B{模型选择}
    B -->|Deepseek| C[DeepseekService]
    B -->|Qianwen| D[QianwenService]
    B -->|其他模型| E[扩展模型服务]
    
    C --> F[构建模型请求]
    D --> F
    E --> F
    
    F --> G{响应类型}
    G -->|基础| H[同步调用LLM]
    G -->|流式/SSE| I[异步流式调用LLM]
    
    H --> J[返回完整响应]
    I --> K[返回流式响应]
    
    J --> L[结束请求]
    K --> L
# 3. Memory服务流程
flowchart TD
    A[开始] --> B{操作类型}
    
    B -->|获取记忆| C[查询会话ID]
    C --> D{缓存中存在?}
    D -->|是| E[从Redis获取]
    D -->|否| F[从数据库加载]
    F --> G[更新到Redis]
    E --> H[返回对话历史]
    G --> H
    
    B -->|保存记忆| I[格式化消息]
    I --> J[更新Redis缓存]
    J --> K[异步保存到数据库]
    K --> L[完成保存]
    
    B -->|清除记忆| M[删除会话缓存]
    M --> N[删除数据库记录]
    N --> O[完成清除]
    
    H --> P[结束]
    L --> P
    O --> P
# 4. Prompt服务流程
flowchart TD
    A[开始] --> B[接收角色ID]
    B --> C{角色是否存在}
    C -->|是| D[加载角色提示词]
    C -->|否| E[使用默认提示词]
    
    D --> F[组合系统提示词]
    E --> F
    
    F --> G{是否有自定义参数}
    G -->|是| H[模板参数替换]
    G -->|否| I[使用原始提示词]
    
    H --> J[返回最终提示词]
    I --> J
    
    J --> K[结束]
# 5. Filter服务流程
flowchart TD
    A[开始] --> B[接收用户消息]
    B --> C[敏感词检测]
    
    C --> D{包含敏感词?}
    D -->|是| E[标记为敏感内容]
    D -->|否| F[意图分类]
    
    F --> G{需要RAG?}
    G -->|是| H[标记需要RAG]
    G -->|否| I[标记为普通对话]
    
    E --> J[返回过滤结果]
    H --> J
    I --> J
    
    J --> K[结束]
# 6. RAG服务流程
flowchart TD
    A[开始] --> B[接收查询]
    B --> C[查询向量化]
    C --> D[检索相关文档]
    
    D --> E{找到相关文档?}
    E -->|是| F[文档重排序]
    E -->|否| G[返回空结果]
    
    F --> H[文档摘要生成]
    H --> I[返回检索结果]
    G --> I
    
    I --> J[结束]


# 聊天模块功能拆分开发步骤

根据系统设计，采用渐进式开发策略，按照核心功能优先、复杂度递增的原则，将开发拆分为以下6个步骤：

## 步骤1：基础LLM调用功能
- 实现`base_llm_service.py`接口设计
- 开发`deepseek_service.py`作为首个模型实现
- 构建`llm_factory.py`用于模型选择
- 实现基础响应格式(`response_formatter.py`)
- 开发最小可行的`chat_service.py`

**交付物**：能接收消息并返回AI回复的最简系统

## 步骤2：记忆与会话管理
- 实现`memory_service.py`记忆服务
- 开发`redis_memory.py`存储实现
- 扩展`chat_service.py`支持会话管理
- 添加会话历史记录功能

**交付物**：支持多轮对话且有记忆能力的系统

## 步骤3：提示词与角色模块
- 实现`prompt_service.py`提示词管理
- 开发`user_prompts.py`用户提示词定义
- 创建`system_prompts.py`系统（角色）提示词
- 扩展`chat_service.py`支持角色切换

**交付物**：支持角色扮演和自定义提示词的系统

## 步骤4：高级响应格式
- 实现`stream_formatter.py`流式响应
- 开发`sse_formatter.py` SSE响应格式
- 扩展LLM服务支持流式调用
- 更新`chat_service.py`支持响应格式选择

**交付物**：支持多种响应格式的交互体验增强系统

## 步骤5：内容过滤系统
- 实现`content_filter.py`过滤服务
- 开发`sensitive_words.py`敏感词检测
- 创建`intent_classifier.py`意图分类
- 扩展`chat_service.py`集成过滤逻辑

**交付物**：具备内容安全与意图识别能力的系统

## 步骤6：RAG知识增强
- 实现`rag_service.py`检索服务
- 开发`document_store.py`文档存储
- 扩展`chat_service.py`支持知识检索增强
- 与过滤系统集成触发RAG的条件判断

**交付物**：具备知识检索增强能力的完整系统

每个步骤都建立在前一步骤的基础上，形成螺旋式上升的开发过程，并且每步结束都有可工作的功能模块。这种拆分方式既满足"功能单一的类，处理单一功能"的设计原则，又确保了系统可以逐步增强而不影响已有功能。

app/
├── services/
│   ├── ai/
│   │   ├── llm.py             # 扩展现有LLM服务，添加角色相关性评估功能
│   │   └── role_selector.py   # 新增：角色选择器服务
│   │
│   ├── chat_service.py        # 扩展现有聊天服务，集成角色选择逻辑
│   └── session_service.py     # (已修改完成，支持system_prompt)
│
├── models/
│   ├── schemas/
│   │   └── role_selection.py  # 新增：角色选择的请求/响应模型
│
└── api/
    └── endpoints/
        └── chat.py            # 修改聊天接口，支持自动角色选择


# 聊天服务与LangChain集成完整设计方案

## 一、现有系统分析

### 1.1 项目结构

项目遵循标准Flask/FastAPI架构，主要模块包括：

- **api**: 接口层，现有`/api/llm`路由处理聊天功能
- **services**: 服务层，包含AI相关服务
- **models**: 数据模型，包括实体和架构
- **static**: 前端界面，已绑定到`/api/llm`接口

### 1.2 已实现功能

- **角色管理**: 完整的CRUD操作(`/api/roles`)
- **会话管理**: 自定义会话控制
- **前端UI**: 基于SSE的实时聊天界面
- **存储层**: MongoDB持久化存储，Redis缓存

### 1.3 存在问题

- 缺乏统一的记忆管理机制
- 角色提示词与聊天功能未完全集成
- 缺乏LangChain提示词模板支持
- 情感和动作等特殊功能支持不完善

## 二、系统架构设计

### 2.1 总体架构

```
app/
├── services/
│   ├── ai/
│   │   ├── memory/
│   │   │   └── memory_service.py    # 记忆服务
│   │   ├── prompt/
│   │   │   └── prompt_service.py    # 提示词服务
│   │   ├── llm/
│   │   │   ├── base_llm_service.py  # 基础模型服务
│   │   │   ├── deepseek_service.py  # 具体实现
│   │   │   └── llm_factory.py       # 工厂类
│   │   └── chat_service.py          # 聊天服务(协调者)
│   │
├── api/
│   └── endpoints/
│       └── llm.py                   # 保持现有路由
│
├── models/
    ├── entities/
    │   └── mongo_models.py          # 添加ChatHistory
    └── schemas/
        ├── message.py               # 消息模型
        └── role.py                  # 角色模型(已有)
```

### 2.2 数据流程

```
用户请求 → API接口(/api/llm) → 聊天服务(ChatService) 
           ↓                      ↑    ↑
       请求验证                记忆服务  提示词服务
           ↓                   ↓     ↓
        参数解析           Redis/MongoDB  角色数据
           ↓                      ↓
         SSE响应 ← 流式输出 ← LLM调用
```

## 三、核心组件设计

### 3.1 记忆服务 (Memory Service)

**职责**: 管理会话历史记录，短期使用Redis，长期存储在MongoDB

```python
# app/services/ai/memory/memory_service.py
class MemoryService:
    async def add_message(self, session_id: str, message: Message) -> None:
        """添加消息到历史记录，Redis(48h)和MongoDB双存储"""
        # Redis短期存储，设置48小时TTL
        # MongoDB长期存储，支持恢复和分析
    
    async def get_history(self, session_id: str, limit: int = 50) -> List[Message]:
        """获取会话历史，优先Redis，降级MongoDB"""
        # 优先从Redis获取最近消息
        # Redis无数据则从MongoDB加载
        # 自动处理反序列化
    
    async def clear_history(self, session_id: str) -> bool:
        """清除指定会话的历史记录"""
        # 同时清除Redis和MongoDB中的记录
```

### 3.2 提示词服务 (Prompt Service)

**职责**: 管理角色提示词，集成LangChain模板

```python
# app/services/ai/prompt/prompt_service.py
class PromptService:
    async def get_role(self, role_id: str) -> Optional[RoleResponse]:
        """获取角色信息，优先Redis缓存"""
        # Redis键格式: role:{role_id}
        # 缓存未命中则从MongoDB获取并更新Redis
    
    def create_prompt_template(self, role: RoleResponse) -> ChatPromptTemplate:
        """创建LangChain提示词模板"""
        # 集成系统提示词、角色特性、特殊标记说明
        # 使用MessagesPlaceholder整合历史消息
    
    def format_history_for_prompt(self, history: List[Message]) -> List[Dict[str, str]]:
        """将历史消息转换为LangChain格式"""
        # 用户消息 → human
        # 助手消息 → ai
        # 系统消息 → system
    
    async def generate_prompt(self, role_id: str, history: List[Message], input_text: str) -> Dict[str, Any]:
        """生成完整的提示词参数"""
        # 获取角色、创建模板、格式化历史、应用温度参数
```

### 3.3 聊天服务 (Chat Service)

**职责**: 协调整体聊天流程，处理特殊标记

```python
# app/services/ai/chat_service.py
class ChatService:
    async def process_message(
        self, 
        session_id: str, 
        message: MessageCreate, 
        role_id: str
    ) -> AsyncGenerator[str, None]:
        """处理消息并生成流式回复"""
        # 1. 保存用户消息
        # 2. 获取历史记录
        # 3. 生成提示词
        # 4. 调用LLM服务
        # 5. 解析特殊标记
        # 6. 流式返回响应
        # 7. 保存AI响应
```

### 3.4 消息模型

```python
# app/models/schemas/message.py
class Message(BaseModel):
    """完整消息模型"""
    role: str  # user, assistant, system
    content: str
    timestamp: str
    metadata: Optional[Dict[str, Any]] = {}

class MessageCreate(BaseModel):
    """创建消息输入"""
    role: str
    content: str
    metadata: Optional[Dict[str, Any]] = {}
```

### 3.5 聊天历史实体

```python
# 添加到app/models/entities/mongo_models.py
class ChatHistory(MongoModel):
    """聊天历史记录模型"""
    _collection_name = "chat_histories"
    
    session_id: str
    messages: List[Dict[str, Any]] = []  # 序列化的Message对象列表
    created_at: datetime = None
    updated_at: datetime = None
```

## 四、提示词模板设计

### 4.1 系统提示词组成

```
{基础系统提示词}

【个性特点】: {role.personality}

【语言风格】: {role.speech_style}

【情感表达】: 当你想表达情感时，请使用[情感:喜悦]这样的格式。

【动作描述】: 当你想描述动作时，请使用[动作:思考]这样的格式。

【敏感内容】: 拒绝讨论政治敏感、暴力、色情等不适当内容。
```

### 4.2 关键占位符

- **历史记录**: `MessagesPlaceholder(variable_name="history")`
- **用户输入**: `{input}`
- **情感标记**: `[情感:xxx]` - 支持喜悦、思考、疑惑等情感标记
- **动作标记**: `[动作:xxx]` - 支持点头、摇头、思考等动作描述
- **温度参数**: 通过角色设置或API参数控制

### 4.3 LangChain模板示例

```python
ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(system_template),
    MessagesPlaceholder(variable_name="history"),
    HumanMessagePromptTemplate.from_template("{input}")
])
```

## 五、API接口设计

保持与现有前端兼容，继续使用`/api/llm`路由：

```python
# app/api/endpoints/llm.py

@router.post("/chat/{session_id}")
async def chat(
    session_id: str,
    message: MessageCreate,
    role_id: str = Query(..., description="角色ID"),
    redis: aioredis.Redis = Depends(get_redis_client),
    history_repo = Depends(get_history_repository),
    role_repo = Depends(get_role_repository)
):
    """聊天接口，支持SSE流式回复"""
    # 初始化服务
    memory_service = MemoryService(redis_client=redis, history_repo=history_repo)
    prompt_service = PromptService(redis_client=redis, role_repo=role_repo)
    chat_service = ChatService(memory_service, prompt_service, redis)
    
    # 创建事件流
    async def event_generator():
        async for chunk in chat_service.process_message(session_id, message, role_id):
            yield f"data: {chunk}\n\n"
        yield "data: {\"done\": true}\n\n"
    
    return StreamingResponse(event_generator(), media_type="text/event-stream")
```

## 六、特殊标记处理

### 6.1 情感标记解析

```python
# 解析[情感:...]标记
emotion_match = re.search(r'\[情感:(.*?)\]', content)
if emotion_match:
    emotion = emotion_match.group(1)
    content = content.replace(emotion_match.group(0), "")
    response["emotion"] = emotion
```

### 6.2 动作标记解析

```python
# 解析[动作:...]标记
action_match = re.search(r'\[动作:(.*?)\]', content)
if action_match:
    action = action_match.group(1)
    content = content.replace(action_match.group(0), "")
    response["action"] = action
```

## 七、实现步骤

### 7.1 准备工作

1. **确认依赖关系**：添加LangChain到项目依赖
2. **创建目录结构**：按设计创建必要目录

### 7.2 创建各组件

1. **消息模型**：实现`app/models/schemas/message.py`
2. **聊天历史**：添加`ChatHistory`到`mongo_models.py`
3. **记忆服务**：实现`memory_service.py`
4. **提示词服务**：实现`prompt_service.py`
5. **聊天服务**：实现`chat_service.py`

### 7.3 添加依赖项

```python
# 添加到app/api/deps.py
async def get_history_repository() -> MongoRepository:
    """获取聊天历史仓库"""
    from app.services.storage.mongo_service import MongoService
    mongo_service = MongoService()
    return MongoRepository(ChatHistory, mongo_service)
```

### 7.4 更新API接口

更新`app/api/endpoints/llm.py`集成新组件

### 7.5 测试与验证

1. 验证记忆功能(会话保留与恢复)
2. 验证角色提示词正确应用
3. 测试特殊标记解析(情感、动作)

## 八、后续扩展方向

1. **内容过滤**：实现敏感词检测和意图分类
2. **RAG知识增强**：添加文档检索和知识库集成
3. **多模型支持**：扩展LLM工厂支持更多模型
4. **响应格式优化**：细化SSE格式支持更多前端交互


