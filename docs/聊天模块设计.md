对系统模型服务进行设计。
1、使用langchain 管理记忆、多模型切换 、支持根据角色选择使用prompt 、根据敏感词、日常沟通判断是否执行回复和rag调用 
2、回复支持 基础、 流式 、sse 
3、抽象出功能单一的类，处理单一功能
4、配置模型配置从.env中获取
# 系统架构图
app/
├── services/
│   ├── ai/
│   │   ├── llm/
│   │   │   ├── base_llm_service.py      # 基础模型服务接口
│   │   │   ├── deepseek_service.py      # Deepseek模型实现
│   │   │   ├── qianwen_service.py       # qianwen模型实现（可选）
│   │   │   └── llm_factory.py           # 模型工厂
│   │   │
│   │   ├── memory/
│   │   │   ├── memory_service.py        # 记忆服务
│   │   │   └── redis_memory.py          # Redis记忆实现
│   │   │
│   │   ├── prompt/
│   │   │   ├── prompt_service.py        # 提示词服务
│   │   │   ├── role_prompts.py          # 角色提示词
│   │   │   └── system_prompts.py        # 系统提示词
│   │   │
│   │   ├── filter/
│   │   │   ├── content_filter.py        # 内容过滤服务
│   │   │   ├── sensitive_words.py       # 敏感词处理
│   │   │   └── intent_classifier.py     # 意图分类
│   │   │
│   │   ├── rag/
│   │   │   ├── rag_service.py           # RAG检索服务
│   │   │   └── document_store.py        # 文档存储
│   │   │
│   │   └── response/
│   │       ├── response_formatter.py    # 响应格式化
│   │       ├── sse_formatter.py         # SSE格式化
│   │       └── stream_formatter.py      # 流式格式化
│   │
│   └── chat_service.py                  # 聊天服务（编排各组件）

# 1. 整体聊天流程
sequenceDiagram
    participant User
    participant ChatService
    participant FilterService
    participant MemoryService
    participant PromptService
    participant RAGService
    participant LLMService
    participant ResponseService

    User->>ChatService: 发送消息
    ChatService->>FilterService: 内容过滤检查
    
    alt 内容需要过滤
        FilterService-->>ChatService: 拒绝请求
        ChatService-->>User: 返回过滤消息
    else 内容通过
        FilterService-->>ChatService: 内容通过
        ChatService->>MemoryService: 获取历史对话
        MemoryService-->>ChatService: 返回历史对话
        
        ChatService->>PromptService: 获取角色提示词
        PromptService-->>ChatService: 返回提示词
        
        ChatService->>FilterService: 判断是否需要RAG
        
        alt 需要RAG增强
            ChatService->>RAGService: 获取相关文档
            RAGService-->>ChatService: 返回检索结果
        end
        
        ChatService->>LLMService: 调用语言模型
        LLMService-->>ChatService: 返回模型响应
        
        ChatService->>ResponseService: 格式化响应
        ResponseService-->>ChatService: 返回格式化结果
        
        ChatService->>MemoryService: 保存对话历史
        ChatService-->>User: 返回响应
    end
# 2. LLM服务流程
flowchart TD
    A[请求开始] --> B{模型选择}
    B -->|Deepseek| C[DeepseekService]
    B -->|Qianwen| D[QianwenService]
    B -->|其他模型| E[扩展模型服务]
    
    C --> F[构建模型请求]
    D --> F
    E --> F
    
    F --> G{响应类型}
    G -->|基础| H[同步调用LLM]
    G -->|流式/SSE| I[异步流式调用LLM]
    
    H --> J[返回完整响应]
    I --> K[返回流式响应]
    
    J --> L[结束请求]
    K --> L
# 3. Memory服务流程
flowchart TD
    A[开始] --> B{操作类型}
    
    B -->|获取记忆| C[查询会话ID]
    C --> D{缓存中存在?}
    D -->|是| E[从Redis获取]
    D -->|否| F[从数据库加载]
    F --> G[更新到Redis]
    E --> H[返回对话历史]
    G --> H
    
    B -->|保存记忆| I[格式化消息]
    I --> J[更新Redis缓存]
    J --> K[异步保存到数据库]
    K --> L[完成保存]
    
    B -->|清除记忆| M[删除会话缓存]
    M --> N[删除数据库记录]
    N --> O[完成清除]
    
    H --> P[结束]
    L --> P
    O --> P
# 4. Prompt服务流程
flowchart TD
    A[开始] --> B[接收角色ID]
    B --> C{角色是否存在}
    C -->|是| D[加载角色提示词]
    C -->|否| E[使用默认提示词]
    
    D --> F[组合系统提示词]
    E --> F
    
    F --> G{是否有自定义参数}
    G -->|是| H[模板参数替换]
    G -->|否| I[使用原始提示词]
    
    H --> J[返回最终提示词]
    I --> J
    
    J --> K[结束]
# 5. Filter服务流程
flowchart TD
    A[开始] --> B[接收用户消息]
    B --> C[敏感词检测]
    
    C --> D{包含敏感词?}
    D -->|是| E[标记为敏感内容]
    D -->|否| F[意图分类]
    
    F --> G{需要RAG?}
    G -->|是| H[标记需要RAG]
    G -->|否| I[标记为普通对话]
    
    E --> J[返回过滤结果]
    H --> J
    I --> J
    
    J --> K[结束]
# 6. RAG服务流程
flowchart TD
    A[开始] --> B[接收查询]
    B --> C[查询向量化]
    C --> D[检索相关文档]
    
    D --> E{找到相关文档?}
    E -->|是| F[文档重排序]
    E -->|否| G[返回空结果]
    
    F --> H[文档摘要生成]
    H --> I[返回检索结果]
    G --> I
    
    I --> J[结束]


# 聊天模块功能拆分开发步骤

根据系统设计，采用渐进式开发策略，按照核心功能优先、复杂度递增的原则，将开发拆分为以下6个步骤：

## 步骤1：基础LLM调用功能
- 实现`base_llm_service.py`接口设计
- 开发`deepseek_service.py`作为首个模型实现
- 构建`llm_factory.py`用于模型选择
- 实现基础响应格式(`response_formatter.py`)
- 开发最小可行的`chat_service.py`

**交付物**：能接收消息并返回AI回复的最简系统

## 步骤2：记忆与会话管理
- 实现`memory_service.py`记忆服务
- 开发`redis_memory.py`存储实现
- 扩展`chat_service.py`支持会话管理
- 添加会话历史记录功能

**交付物**：支持多轮对话且有记忆能力的系统

## 步骤3：提示词与角色系统
- 实现`prompt_service.py`提示词管理
- 开发`role_prompts.py`角色提示词定义
- 创建`system_prompts.py`系统提示词
- 扩展`chat_service.py`支持角色切换

**交付物**：支持角色扮演和自定义提示词的系统

## 步骤4：高级响应格式
- 实现`stream_formatter.py`流式响应
- 开发`sse_formatter.py` SSE响应格式
- 扩展LLM服务支持流式调用
- 更新`chat_service.py`支持响应格式选择

**交付物**：支持多种响应格式的交互体验增强系统

## 步骤5：内容过滤系统
- 实现`content_filter.py`过滤服务
- 开发`sensitive_words.py`敏感词检测
- 创建`intent_classifier.py`意图分类
- 扩展`chat_service.py`集成过滤逻辑

**交付物**：具备内容安全与意图识别能力的系统

## 步骤6：RAG知识增强
- 实现`rag_service.py`检索服务
- 开发`document_store.py`文档存储
- 扩展`chat_service.py`支持知识检索增强
- 与过滤系统集成触发RAG的条件判断

**交付物**：具备知识检索增强能力的完整系统

每个步骤都建立在前一步骤的基础上，形成螺旋式上升的开发过程，并且每步结束都有可工作的功能模块。这种拆分方式既满足"功能单一的类，处理单一功能"的设计原则，又确保了系统可以逐步增强而不影响已有功能。
